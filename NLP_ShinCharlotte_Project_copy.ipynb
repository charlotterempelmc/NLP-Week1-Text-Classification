{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlotterempelmc/NLP-Week1-Text-Classification/blob/main/NLP_ShinCharlotte_Project_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9LBtcg76NbX"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Hello, I'm **Wesley**, nice to meet you!\n",
        "\n",
        "I was just reading the IMDb reviews of [*The Super Mario Bros. Movie*](https://www.imdb.com/title/tt6718170/), I thought why don't we make a **Sentiment Classifier** to categorize movie reviews! **WARNING: Spoilers ahead.**\n",
        "\n",
        "\n",
        "Here we will be doing [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) on BERT [(blog)](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) [(paper)](https://arxiv.org/abs/1810.04805v2) with an IMDb dataset to make a sentiment classifier for movie reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Noh5huE6NbY"
      },
      "source": [
        "# Setup Python Libraries (pip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwX3NojfLKjD",
        "outputId": "ee4e8a87-b126-4567-bd80-d1524211402a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install hf_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtlNVKJR6NbY"
      },
      "outputs": [],
      "source": [
        "#install some Python packages with pip\n",
        "\n",
        "!pip install numpy torch datasets transformers evaluate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjTwjo6u6NbY",
        "outputId": "c6246a12-ec71-49af-9443-2d33fc3c228f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets==4.4.1\n",
            "evaluate==0.4.6\n",
            "numpy==2.1.2\n",
            "torch==2.8.0+cu128\n",
            "torchaudio==2.8.0+cu128\n",
            "torchvision==0.23.0+cu128\n",
            "transformers==4.57.1\n"
          ]
        }
      ],
      "source": [
        "# let's check the version we are using\n",
        "\n",
        "!pip freeze | grep -E '^numpy|^torch|^datasets|^transformers|^evaluate'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AYGJyIo6NbZ"
      },
      "source": [
        "# Create IMDB Dataset for Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtxPz74d6NbZ"
      },
      "source": [
        "## Let's load the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "mNUWKUiYKzcp",
        "outputId": "a7451e4d-078d-4bb3-dc26-8020a848db21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 650000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load our text reviews dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# let's load the imdb dataset from huggingface\n",
        "# source: (https://huggingface.co/datasets/imdb) citizenlab/distilbert-base-multilingual-cased-toxicity\n",
        "\n",
        "raw_dataset = load_dataset('Yelp/yelp_review_full')\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "Hkf8Ari6bSyj",
        "outputId": "c342a52d-9351-436a-f173-8fe0b2e2f16f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 60\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load our text reviews dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# let's load the imdb dataset from huggingface\n",
        "# source: (https://huggingface.co/datasets/imdb) citizenlab/distilbert-base-multilingual-cased-toxicity\n",
        "\n",
        "raw_datasetTest = load_dataset('charlotterempel/testsplit-finalproject')\n",
        "raw_datasetTest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJw7VDtG6NbZ"
      },
      "source": [
        "## Let's create the train, validation, test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhX05VjE6NbZ",
        "outputId": "1e00efd3-d29d-4f15-d03c-2a37aabeea2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 520000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 130000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get train and validation set\n",
        "\n",
        "dataset = raw_dataset['train'].train_test_split(test_size=0.2, seed=42, shuffle=True)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmwBXU6c6Nba"
      },
      "outputs": [],
      "source": [
        "# rename validation key to 'val'\n",
        "\n",
        "dataset['val'] = dataset['test']\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckEa_4vQ6Nba",
        "outputId": "934982e1-06a5-4c3c-8b13-de2b9e3943c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 520000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 130000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# copy test set from raw_dataset\n",
        "\n",
        "dataset['test'] = raw_dataset['test']\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-AIsm5z6Nba"
      },
      "source": [
        "## We start by tokenizing our dataset with the BERT's Fast Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "2fRaHrivLLR7",
        "outputId": "7dae3b02-67c3-4fa3-de3d-33ec74731f36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import pretrained faster tokenizer from huggingface\n",
        "# source: (https://huggingface.co/ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = 'ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "59c3f9826dfe49609a82a3e54dc532fa"
          ]
        },
        "id": "UJs4EM6_6Nba",
        "outputId": "dc89aabb-4d6c-4f55-dbca-793f55cc2d48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59c3f9826dfe49609a82a3e54dc532fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/130000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 520000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 130000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenize the text in batches with truncation and padding based on BERT requirements\n",
        "\n",
        "def tokenization(example):\n",
        "    return tokenizer(example['text'], truncation=True, padding=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenization, batched=True, remove_columns=['text'])\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "OYOk0R3DbkHr",
        "outputId": "e2c9ddee-83d1-4de5-cfff-3bf79baf384b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 60\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#tokenize test split\n",
        "# tokenize the text in batches with truncation and padding based on BERT requirements\n",
        "\n",
        "def tokenization(example):\n",
        "    return tokenizer(example['text'], truncation=True, padding=True)\n",
        "\n",
        "tokenized_datasetTest = raw_datasetTest.map(tokenization, batched=True, remove_columns=['text'])\n",
        "tokenized_datasetTest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruQcvQDs6Nba"
      },
      "source": [
        "# Setup Training Metrics (Accuracy, F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnkE1H3lLKjG",
        "outputId": "b1b9d3d9-6eac-46ca-da3f-26c9b47e8f35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.1.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6nLLwZT6Nba"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# we setup the training to evaluate accuracy, precision, recall & f1 scores\n",
        "\n",
        "accuracy_metric = evaluate.load('accuracy')\n",
        "precision_metric = evaluate.load('precision')\n",
        "recall_metric = evaluate.load('recall')\n",
        "f1_metric = evaluate.load('f1')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    return {**accuracy, **precision, **recall, **f1,}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N87ZQ-a96Nba"
      },
      "source": [
        "# Setup Training Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3XgHs1wLKjH",
        "outputId": "c3c6291d-cc23-4b11-a6a9-c0e0d1e95cd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.8.0+cu128)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (1.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (2025.10.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrTyFbhSLKjH",
        "outputId": "08edbf5e-ea71-4219-f924-5d303bfdfbba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu128)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYiXve5cy4OV"
      },
      "outputs": [],
      "source": [
        "#training 1 - multi-class sentiment analysis (fine-tuning Hugging Face model)\n",
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, IntervalStrategy\n",
        "\n",
        "# get bert model with a sequence classification head for sentiment analysis\n",
        "# source: (https://huggingface.co/ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel)\n",
        "checkpoint = 'ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel'\n",
        "num_labels = 5\n",
        "id2label = {0:'1 star',1:'2 stars',2:'3 stars', 3:'4 stars',4:'5 stars'}\n",
        "label2id = {'1 star':0,'2 stars':1,'3 stars':2,'4 stars':3,'5 stars':4}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# setup custom training arguments\n",
        "# 1. store training checkpoints to 'results' output directory\n",
        "# 2. fine-tune for just 1 epoch\n",
        "# 3,4. use 16 as a batch size to speed things up\n",
        "# 5. evaluate validation set every 500 steps (this is the default steps)\n",
        "# 6. load the best model based on the lowest validation loss at the end of training\n",
        "training_args = TrainingArguments(\n",
        "    seed=42,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    load_best_model_at_end=True,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = 'epoch',\n",
        "    learning_rate = 7e-6\n",
        ")\n",
        "\n",
        "# setup trainer with custom metrics (accuracy, precision, recall & f1)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['val'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# disable wandb logging (a v4 huggingface artifact)\n",
        "os.environ['WANDB_DISABLED']= \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv8k-XerDXiJ",
        "outputId": "5ee2ab13-d85c-4f5d-9ef5-aeacc15fb5fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "#training 2 - multi-class sentiment analysis (fine-tuning Hugging Face model)\n",
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, IntervalStrategy\n",
        "\n",
        "# get bert model with a sequence classification head for sentiment analysis\n",
        "# source: (https://huggingface.co/ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel)\n",
        "checkpoint = 'ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel'\n",
        "num_labels = 5\n",
        "id2label = {0:'1 star',1:'2 stars',2:'3 stars', 3:'4 stars',4:'5 stars'}\n",
        "label2id = {'1 star':0,'2 stars':1,'3 stars':2,'4 stars':3,'5 stars':4}\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# setup custom training arguments\n",
        "# 1. store training checkpoints to 'results' output directory\n",
        "# 2. fine-tune for just 1 epoch\n",
        "# 3,4. use 16 as a batch size to speed things up\n",
        "# 5. evaluate validation set every 500 steps (this is the default steps)\n",
        "# 6. load the best model based on the lowest validation loss at the end of training\n",
        "training_args = TrainingArguments(\n",
        "    seed=42,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    load_best_model_at_end=True,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = 'epoch',\n",
        "    learning_rate = 3e-5\n",
        ")\n",
        "\n",
        "# setup trainer with custom metrics (accuracy, precision, recall & f1)\n",
        "trainer2 = Trainer(\n",
        "    model=model2,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['val'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# disable wandb logging (a v4 huggingface artifact)\n",
        "os.environ['WANDB_DISABLED']= \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byBXp6rALKjH",
        "outputId": "4c94ad09-463f-4a3d-9b20-cba58697c4d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "#training 3 - multi-class sentiment analysis (fine-tuning Hugging Face model)\n",
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, IntervalStrategy\n",
        "\n",
        "# get bert model with a sequence classification head for sentiment analysis\n",
        "# source: (https://huggingface.co/ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel)\n",
        "checkpoint = 'ElizaClaPa/SentimentAnalysis-YelpReviews-OptimizedModel'\n",
        "num_labels = 5\n",
        "id2label = {0:'1 star',1:'2 stars',2:'3 stars', 3:'4 stars',4:'5 stars'}\n",
        "label2id = {'1 star':0,'2 stars':1,'3 stars':2,'4 stars':3,'5 stars':4}\n",
        "model3 = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# setup custom training arguments\n",
        "# 1. store training checkpoints to 'results' output directory\n",
        "# 2. fine-tune for just 1 epoch\n",
        "# 3,4. use 16 as a batch size to speed things up\n",
        "# 5. evaluate validation set every 500 steps (this is the default steps)\n",
        "# 6. load the best model based on the lowest validation loss at the end of training\n",
        "training_args = TrainingArguments(\n",
        "    seed=42,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    load_best_model_at_end=True,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = 'epoch',\n",
        "    learning_rate = 6e-8\n",
        ")\n",
        "\n",
        "# setup trainer with custom metrics (accuracy, precision, recall & f1)\n",
        "trainer3 = Trainer(\n",
        "    model=model3,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['val'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# disable wandb logging (a v4 huggingface artifact)\n",
        "os.environ['WANDB_DISABLED']= \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BheEfcmkQDPn",
        "outputId": "85b88c7b-ab69-4c5a-e29d-c7807bcc16db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8idhO0EW6Nbb"
      },
      "source": [
        "# Evaluate UnFine-Tuned BERT on Test Set for a Baseline Metric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "collapsed": true,
        "id": "MwFsYiOd6Nbb",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d5a296a7-00a6-4712-a2e0-c62d6e97a5a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3159' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 14:07]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.7893904447555542,\n",
              " 'eval_model_preparation_time': 0.0023,\n",
              " 'eval_accuracy': 0.68256,\n",
              " 'eval_f1': 0.6835976156302593,\n",
              " 'eval_runtime': 740.0072,\n",
              " 'eval_samples_per_second': 67.567,\n",
              " 'eval_steps_per_second': 4.223}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate unfine-tuned model with test set\n",
        "\n",
        "trainer.evaluate(tokenized_dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "collapsed": true,
        "id": "lIK5UU1ycGAI",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "bd050336-8744-4085-b21d-ea9f0143ff1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 路路路路路路路路路路\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharlotterempelmc\u001b[0m (\u001b[33mcharlotterempel\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251116_080641-hida05tl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/charlotterempel/huggingface/runs/hida05tl' target=\"_blank\">worthy-wildflower-3</a></strong> to <a href='https://wandb.ai/charlotterempel/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/charlotterempel/huggingface' target=\"_blank\">https://wandb.ai/charlotterempel/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/charlotterempel/huggingface/runs/hida05tl' target=\"_blank\">https://wandb.ai/charlotterempel/huggingface/runs/hida05tl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5010844469070435,\n",
              " 'eval_model_preparation_time': 0.0014,\n",
              " 'eval_accuracy': 0.8,\n",
              " 'eval_precision': 0.7,\n",
              " 'eval_recall': 0.8,\n",
              " 'eval_f1': 0.7333333333333333,\n",
              " 'eval_runtime': 0.8561,\n",
              " 'eval_samples_per_second': 5.84,\n",
              " 'eval_steps_per_second': 1.168}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate unfine-tuned model with own test split\n",
        "\n",
        "trainer.evaluate(tokenized_datasetTest['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS3DVHp06Nbb"
      },
      "source": [
        "Without fine-tuning BERT, our model currently has around **52% Accuracy (eval_accuracy)** and **19% F1 (eval_f1)**, which is pretty bad due to the test dataset having around 50% positive and 50% negative reviews. \n",
        "\n",
        "\n",
        "Let's make it better with transfer learning! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nfw3HCH6Nbb"
      },
      "source": [
        "# Fine-Tune BERT with IMDb Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "2yFGepJdTFl-",
        "outputId": "55aa7d9d-f345-4026-ac3e-7c948829cc25"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32500' max='32500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32500/32500 1:47:11, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.468500</td>\n",
              "      <td>0.415966</td>\n",
              "      <td>0.841685</td>\n",
              "      <td>0.842009</td>\n",
              "      <td>0.841685</td>\n",
              "      <td>0.841766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=32500, training_loss=0.47291602313701925, metrics={'train_runtime': 6432.5914, 'train_samples_per_second': 80.838, 'train_steps_per_second': 5.052, 'total_flos': 6.88867325952e+16, 'train_loss': 0.47291602313701925, 'epoch': 1.0})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fine-tune BERT with the yelp dataset (changed 1 hyperparameter: learning rate)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk0s1IbOB94o"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"trainedModelOne\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycBroP8nCpWt",
        "outputId": "18448d29-bcdc-4bf7-c25e-e103c230e944"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32500' max='32500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32500/32500 1:46:50, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.515900</td>\n",
              "      <td>0.475856</td>\n",
              "      <td>0.811900</td>\n",
              "      <td>0.812330</td>\n",
              "      <td>0.811900</td>\n",
              "      <td>0.812023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=32500, training_loss=0.5359185208834134, metrics={'train_runtime': 6410.7088, 'train_samples_per_second': 81.114, 'train_steps_per_second': 5.07, 'total_flos': 6.88867325952e+16, 'train_loss': 0.5359185208834134, 'epoch': 1.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFiouM9jCqyX"
      },
      "outputs": [],
      "source": [
        "trainer2.save_model(\"trainedModelTwo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYtKLkmtCsFO",
        "outputId": "ba4eae87-92d9-46b4-c468-12d9d864a360"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.0076663494110107,\n",
              " 'eval_accuracy': 0.6166666666666667,\n",
              " 'eval_precision': 0.6640756302521008,\n",
              " 'eval_recall': 0.6166666666666667,\n",
              " 'eval_f1': 0.6039297416579363,\n",
              " 'eval_runtime': 0.1563,\n",
              " 'eval_samples_per_second': 383.825,\n",
              " 'eval_steps_per_second': 25.588,\n",
              " 'epoch': 1.0}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer2.evaluate(tokenized_datasetTest['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlkIr27OCCFa"
      },
      "outputs": [],
      "source": [
        "##############################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uervImH5LKjI",
        "outputId": "a0d7fd13-9b9f-42bd-e517-6cef495bc237"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32500' max='32500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32500/32500 1:47:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.484900</td>\n",
              "      <td>0.446563</td>\n",
              "      <td>0.826754</td>\n",
              "      <td>0.827290</td>\n",
              "      <td>0.826754</td>\n",
              "      <td>0.826839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=32500, training_loss=0.4873717017540565, metrics={'train_runtime': 6425.3172, 'train_samples_per_second': 80.93, 'train_steps_per_second': 5.058, 'total_flos': 6.88867325952e+16, 'train_loss': 0.4873717017540565, 'epoch': 1.0})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer3.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zVft3q2LKjX"
      },
      "outputs": [],
      "source": [
        "trainer3.save_model(\"model3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "collapsed": true,
        "id": "4Mq4E7cgjEn7",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "970315de-dc38-4c7d-e026-ff09373ba169"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
            "\tlogging_steps: 500 (from args) != 5000 (from trainer_state.json)\n",
            "\teval_steps: 500 (from args) != 5000 (from trainer_state.json)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1115' max='32500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1115/32500 01:22 < 6:21:45, 1.37 it/s, Epoch 0.03/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3888828700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#continue training trainer2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/checkpoints/checkpoint-1000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2677\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m                     ):\n\u001b[1;32m   2681\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# continue training trainer2\n",
        "# trainer2.train(resume_from_checkpoint='/content/drive/MyDrive/checkpoints/checkpoint-1000')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNJyPNrCendb"
      },
      "outputs": [],
      "source": [
        "trainer2.evaluate(tokenized_dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uZ4CEH06Nbc"
      },
      "outputs": [],
      "source": [
        "# let's see how well it did in the test set\n",
        "\n",
        "trainer.evaluate(tokenized_dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMLn_ZFEQiFj"
      },
      "outputs": [],
      "source": [
        "# trainer.save(\"myfinalmodel\") #save & download it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-3yDLk06Nbc"
      },
      "source": [
        "**WOAH!** We got a **92% Accuracy (eval_accuracy)** and **92% F1 (eval_f1)** with just **1 epoch**! く"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LOx99ZT6Nbc"
      },
      "source": [
        "# Try out some examples!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zTZwEcD6Nbc"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# get current device with pytorch\n",
        "device = torch.cuda.current_device()\n",
        "\n",
        "# create pipeline for sentiment classifier with custom model and tokenizer\n",
        "sentiment_classifier = pipeline(task='sentiment-analysis', model=model, tokenizer=tokenizer, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I66xCdD06Nbc",
        "outputId": "5d2afd34-3485-4797-f211-5fa886d0ce11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9938808679580688}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's see how our model classifies a good review\n",
        "# this is from 'justinvitelli' (https://www.imdb.com/review/rw8972952)\n",
        "\n",
        "review = \"\"\"\n",
        "First off this movie is for kids and fans of Nintendo and the Mario franchise.\n",
        "I still think an adult who isnt a fan could still enjoy it but this movie is so\n",
        "full of fan service that it will have you smiling the whole time.\n",
        "The voice acting I was skeptical but they all work and work well too.\n",
        "Jack Black is the star here. I love how they kept the story simple like all of the games.\n",
        "Truly felt like a video game on screen.\n",
        "This movie felt like a beautifully animated amusement park ride.\n",
        "The audio in the movie was amazing too.\n",
        "The sounds and the score with reimagined iconic music was perfect.\n",
        "Some of the songs in the movie felt unnecessary but they worked.\n",
        "I think they should've bumped the run time to 105-120 min.\n",
        "90 min felt too short as it goes by quick.\n",
        "I havent had this much wholesome fun at the movies in a long time.\n",
        "If youre a fan you HAVE to see it.\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw6RDxiR6Nbc"
      },
      "source": [
        "That is **99% POSITIVE**! *justinvitelli* loves the movie!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zdT42K86Nbc",
        "outputId": "f08b9fda-e83b-4983-ee7c-97544e18aa15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9951890707015991}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's see how our model classifies a bad review\n",
        "# this is from 'industriousbug16' (https://www.imdb.com/review/rw8998214)\n",
        "\n",
        "review = \"\"\"\n",
        "Flat, visual noise.\n",
        "Fundamentally incurious. Potentially injurious.\n",
        "The mystique generated by the characters in the games is here raked over and presented\n",
        "haphazardly by hacks.\n",
        "A hobbled attempt to explain a long and random evolution of characters who were never meant\n",
        "to be narratised fails.\n",
        "Doing it well is near impossible when you insist on EVERY LITTLE BIT OF LORE,\n",
        "from the last forty years being shoehorned into 90 minutes.\n",
        "Makes little sense, shamelessly leans on member berries to stimulate older viewers but offers\n",
        "nothing else.\n",
        "I feel sad for the animators who did a sterling job, but to no end as this movie has no soul.\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "checkpoint = \"charlotterempel/fine-tuned-shinCharlotte\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "sentiment_classifier(\"HORRIBLE SERVICE. Thank you for giving me absolute hell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxTLTGw9L20j",
        "outputId": "a4d9eabc-7cef-4647-e94b-78ad342a66d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '1 star', 'score': 0.9955578446388245}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "checkpoint = \"charlotterempel/fine-tuned-shinCharlotte\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "sentiment_classifier(\"DISGUSTING. What an absolute nightmare...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7scJeLk0RnX0",
        "outputId": "c516aafe-e2a7-402a-e171-1f99efab4a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '1 star', 'score': 0.9944145679473877}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "checkpoint = \"charlotterempel/fine-tuned-shinCharlotte\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "sentiment_classifier(\"These sunglasses are the most beautiful thing i have ever worn, you won't regret it!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhlwgGZgS3DB",
        "outputId": "a73342a1-a3c8-4ef5-d3a7-e421a5f18755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '5 stars', 'score': 0.97735196352005}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "checkpoint = \"charlotterempel/fine-tuned-shinCharlotte\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "sentiment_classifier(\"This leather jacket was pretty good. But for the price, i wish it didn't smell bad but overall decent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z75d7kvYUbJD",
        "outputId": "8414c2ee-a10d-42a9-9da2-cdacc0178c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '3 stars', 'score': 0.8761754631996155}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "checkpoint = \"charlotterempel/fine-tuned-shinCharlotte\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "sentiment_classifier(\"mid bro.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COhrc411YiaY",
        "outputId": "a05e4b71-285c-45be-a148-47dafc7292fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '2 stars', 'score': 0.49382418394088745}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "checkpoint = \"charlotterempel/fine-tuned-shinCharlotte\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "\n",
        "sentiment_classifier(\"This was bangin, absolute smash! Wowzas.\")"
      ],
      "metadata": {
        "id": "G4azrWSCYrRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYjwORcN6Nbc"
      },
      "source": [
        "That is **99% NEGATIVE**! *industriousbug16* must hate the movie very badly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77tIkhXi6Nbd"
      },
      "source": [
        "# Resources\n",
        "\n",
        "### If you would like to use this model without running the entire notebook, try the model at my [HuggingFace](https://huggingface.co/wesleyacheng/movie-review-sentiment-classifier-with-bert).\n",
        "\n",
        "### If you woud like to get this in GitHub, here's my [repo](https://github.com/wesleyacheng/movie-review-sentiment-classifier-with-bert)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}